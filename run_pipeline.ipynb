{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ROBUST04 Ranking Pipeline\n",
        "\n",
        "**Architecture (6-Way Hybrid + Neural + LLM Cascade):**\n",
        "- **Run 1:** BM25(orig) + Dense(orig) + **SPLADE(orig)** + BM25(Q2D) + Dense(Q2D) + **SPLADE(Q2D)** → RRF\n",
        "- **Run 2:** Run 1 candidates → Bi-Encoder filter → CE+MonoT5 → MaxP\n",
        "- **Run 3:** Weighted RRF(Run1, Run2, LLM)\n",
        "\n",
        "**Key Optimizations:**\n",
        "- **SPLADE retrieval** (+24% recall on hard queries like \"unexplained highway accidents\")\n",
        "- **Bi-encoder pre-filtering** (3x faster neural reranking)\n",
        "- Query2Doc expansions (1990s vocabulary)\n",
        "- Dynamic few-shot selection for LLM\n",
        "\n",
        "**Models:** SPLADE++, BGE-large (bi-encoder), BGE-reranker-v2-m3 + MiniLM-L12, MonoT5-large, gpt-4o-mini + gpt-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (restart runtime after if you see Pillow errors)\n",
        "!apt-get update -qq && apt-get install -qq openjdk-21-jdk-headless > /dev/null 2>&1\n",
        "%pip uninstall -q -y gradio gradio-client 2>/dev/null\n",
        "%pip install -q pyserini faiss-cpu torch transformers sentence-transformers \\\n",
        "    pytrec_eval langchain-text-splitters tqdm accelerate openai 2>/dev/null\n",
        "print(\"✓ Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "%cd /content\n",
        "!rm -rf text-retrieval-and-search-engines\n",
        "!git clone https://github.com/er1009/text-retrieval-and-search-engines.git\n",
        "%cd text-retrieval-and-search-engines/final-project\n",
        "print(\"\\n✓ Repository cloned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set OpenAI API key\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-YOUR-API-KEY-HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive and setup dense index path\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "INDEX_PATH = \"/content/drive/MyDrive/robust04_dense_index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-download BM25 index (models downloaded on-demand during pipeline)\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "searcher = LuceneSearcher.from_prebuilt_index(\"robust04\")\n",
        "print(f\"✓ BM25 index cached: {searcher.num_docs:,} documents\")\n",
        "searcher.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build or load dense index (~45 min first time, instant after)\n",
        "# BGE-small: best quality/speed tradeoff (512 tokens = 1500 chars)\n",
        "!python -m src.dense_index \\\n",
        "    --index-path \"/content/drive/MyDrive/robust04_dense_index\" \\\n",
        "    --embedding-model \"BAAI/bge-small-en-v1.5\" \\\n",
        "    --chunk-size 1500 \\\n",
        "    --chunk-overlap 200 \\\n",
        "    --batch-size 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: Build SPLADE Index (~1.5-2 hours on A100)\n",
        "\n",
        "SPLADE (Sparse Lexical and Expansion) learns term importance and query expansion.\n",
        "This can **improve recall by 3-5%** over BM25 by finding documents that match\n",
        "semantically but not lexically (e.g., \"unexplained accidents\" → \"mysterious crash\").\n",
        "\n",
        "**Only run this if you have compute budget and want to try SPLADE retrieval.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build SPLADE index (~1.5-2 hours on A100, ~45 min on H100)\n",
        "# Uses learned sparse retrieval for better term expansion\n",
        "# Skip this cell if you don't have compute budget\n",
        "\n",
        "SPLADE_INDEX_PATH = \"/content/drive/MyDrive/robust04_splade_index\"\n",
        "\n",
        "!python -m src.splade_index \\\n",
        "    --index-path \"{SPLADE_INDEX_PATH}\" \\\n",
        "    --model-name \"naver/splade-cocondenser-ensembledistil\" \\\n",
        "    --chunk-size 1500 \\\n",
        "    --chunk-overlap 200 \\\n",
        "    --batch-size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test SPLADE index (quick verification)\n",
        "from src.splade_index import SpladeIndex\n",
        "\n",
        "splade = SpladeIndex(\"/content/drive/MyDrive/robust04_splade_index\")\n",
        "splade.load()\n",
        "\n",
        "# Test search\n",
        "results = splade.search(\"unexplained highway accidents\", top_k=10)\n",
        "print(\"Top 10 results for 'unexplained highway accidents':\")\n",
        "for docid, score in list(results.items())[:10]:\n",
        "    print(f\"  {docid}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare retrieval methods: BM25 vs Dense vs SPLADE (optional analysis)\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "from src.dense_index import DensePassageIndex\n",
        "from src.splade_index import SpladeIndex\n",
        "import pytrec_eval\n",
        "\n",
        "# Load qrels\n",
        "qrels = {}\n",
        "with open(\"Files-20260103/qrels_50_Queries\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        qid, docid, rel = parts[0], parts[2], int(parts[3])\n",
        "        if qid not in qrels: qrels[qid] = {}\n",
        "        qrels[qid][docid] = rel\n",
        "\n",
        "# Test on one hard query\n",
        "test_query = \"unexplained highway accidents\"\n",
        "test_qid = \"315\"\n",
        "\n",
        "# BM25\n",
        "bm25 = LuceneSearcher.from_prebuilt_index(\"robust04\")\n",
        "bm25_results = {h.docid: h.score for h in bm25.search(test_query, k=1000)}\n",
        "\n",
        "# Dense\n",
        "dense = DensePassageIndex(\"/content/drive/MyDrive/robust04_dense_index\")\n",
        "dense.load()\n",
        "dense_results = dense.search(test_query, top_k=1000)\n",
        "\n",
        "# SPLADE\n",
        "splade = SpladeIndex(\"/content/drive/MyDrive/robust04_splade_index\")\n",
        "splade.load()\n",
        "splade_results = splade.search(test_query, top_k=1000)\n",
        "\n",
        "# Evaluate\n",
        "evaluator = pytrec_eval.RelevanceEvaluator({test_qid: qrels[test_qid]}, {\"recall_1000\", \"map\"})\n",
        "\n",
        "print(f\"Query {test_qid}: '{test_query}'\")\n",
        "print(f\"  Relevant docs: {sum(1 for r in qrels[test_qid].values() if r > 0)}\")\n",
        "print()\n",
        "for name, results in [(\"BM25\", bm25_results), (\"Dense\", dense_results), (\"SPLADE\", splade_results)]:\n",
        "    e = evaluator.evaluate({test_qid: results})\n",
        "    print(f\"  {name:8s}: R@1000={e[test_qid]['recall_1000']:.3f}  MAP={e[test_qid]['map']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Sanity Check (5 queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sanity check with SPLADE (~3-5 min with bi-encoder)\n",
        "# Now uses 6-way hybrid: BM25(orig) + Dense(orig) + SPLADE(orig) + BM25(Q2D) + Dense(Q2D) + SPLADE(Q2D)\n",
        "!python -m src.main train \\\n",
        "    --output-dir results_sanity \\\n",
        "    --dense-index-path \"/content/drive/MyDrive/robust04_dense_index\" \\\n",
        "    --splade-index-path \"/content/drive/MyDrive/robust04_splade_index\" \\\n",
        "    --limit-queries 5 \\\n",
        "    --retrieval-k 2000 \\\n",
        "    --rerank-depth 1000 \\\n",
        "    --chunk-size 512 \\\n",
        "    --chunk-overlap 64 \\\n",
        "    --use-bi-encoder \\\n",
        "    --bi-encoder-model \"BAAI/bge-large-en-v1.5\" \\\n",
        "    --bi-encoder-ratio 2.0 \\\n",
        "    --ce-model \"BAAI/bge-reranker-v2-m3,cross-encoder/ms-marco-MiniLM-L-12-v2\" \\\n",
        "    --monot5-model \"castorini/monot5-large-msmarco\" \\\n",
        "    --ce-batch-size 256 \\\n",
        "    --monot5-batch-size 64 \\\n",
        "    --ce-weight 0.5 \\\n",
        "    --neural-weight 0.8 \\\n",
        "    --rrf-k 60 \\\n",
        "    --rrf-weight-run1 1.0 \\\n",
        "    --rrf-weight-run2 1.0 \\\n",
        "    --rrf-weight-llm 1.0 \\\n",
        "    --llm-model \"gpt-4o-mini\" \\\n",
        "    --llm-top-k 50 \\\n",
        "    --llm-window-size 10 \\\n",
        "    --llm-step-size 5 \\\n",
        "    --llm-max-passage-length 1500 \\\n",
        "    --llm-concurrency 10 \\\n",
        "    --llm-strong-model \"gpt-5\" \\\n",
        "    --llm-strong-top-k 20 \\\n",
        "    --llm-dynamic-few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-query analysis (optional - helps debug)\n",
        "import pytrec_eval\n",
        "\n",
        "qrels = {}\n",
        "with open(\"Files-20260103/qrels_50_Queries\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        qid, docid, rel = parts[0], parts[2], int(parts[3])\n",
        "        if qid not in qrels: qrels[qid] = {}\n",
        "        qrels[qid][docid] = rel\n",
        "\n",
        "queries = {}\n",
        "with open(\"Files-20260103/queriesROBUST.txt\") as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) >= 2: queries[parts[0]] = parts[1]\n",
        "\n",
        "def load_run(path):\n",
        "    run = {}\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            qid, docid, score = parts[0], parts[2], float(parts[4])\n",
        "            if qid not in run: run[qid] = {}\n",
        "            run[qid][docid] = score\n",
        "    return run\n",
        "\n",
        "r1 = load_run(\"results_sanity/run_1.res\")\n",
        "r2 = load_run(\"results_sanity/run_2.res\")\n",
        "r3 = load_run(\"results_sanity/run_3.res\")\n",
        "\n",
        "evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'map', 'recall_1000'})\n",
        "e1, e2, e3 = evaluator.evaluate(r1), evaluator.evaluate(r2), evaluator.evaluate(r3)\n",
        "\n",
        "print(\"=\" * 85)\n",
        "print(f\"{'QID':<6} {'Query':<35} {'Run1':>10} {'Run2':>10} {'Run3':>10} {'R@1000':>8}\")\n",
        "print(\"-\" * 85)\n",
        "for qid in sorted(e1.keys(), key=lambda x: int(x)):\n",
        "    q = queries.get(qid, \"N/A\")[:32]\n",
        "    print(f\"{qid:<6} {q:<35} {e1[qid]['map']:>10.4f} {e2[qid]['map']:>10.4f} {e3[qid]['map']:>10.4f} {e1[qid]['recall_1000']:>8.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1b. Ablation Tests (Optional)\n",
        "\n",
        "Test whether Q2D and LLM actually help:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ABLATION 1: No Q2D (original queries only)\n",
        "!python -m src.main train \\\n",
        "    --output-dir results_no_q2d \\\n",
        "    --dense-index-path \"/content/drive/MyDrive/robust04_dense_index\" \\\n",
        "    --limit-queries 5 \\\n",
        "    --disable-q2d \\\n",
        "    --retrieval-k 2000 \\\n",
        "    --rerank-depth 1000 \\\n",
        "    --chunk-size 512 \\\n",
        "    --chunk-overlap 64 \\\n",
        "    --use-bi-encoder \\\n",
        "    --bi-encoder-model \"BAAI/bge-large-en-v1.5\" \\\n",
        "    --bi-encoder-ratio 2.0 \\\n",
        "    --ce-model \"BAAI/bge-reranker-v2-m3,cross-encoder/ms-marco-MiniLM-L-12-v2\" \\\n",
        "    --monot5-model \"castorini/monot5-large-msmarco\" \\\n",
        "    --ce-batch-size 256 \\\n",
        "    --monot5-batch-size 64 \\\n",
        "    --ce-weight 0.5 \\\n",
        "    --neural-weight 0.8 \\\n",
        "    --rrf-k 60 \\\n",
        "    --rrf-weight-run1 1.0 \\\n",
        "    --rrf-weight-run2 1.0 \\\n",
        "    --rrf-weight-llm 1.0 \\\n",
        "    --llm-model \"gpt-4o-mini\" \\\n",
        "    --llm-top-k 50 \\\n",
        "    --llm-window-size 10 \\\n",
        "    --llm-step-size 5 \\\n",
        "    --llm-max-passage-length 1500 \\\n",
        "    --llm-concurrency 10 \\\n",
        "    --llm-strong-model \"gpt-5\" \\\n",
        "    --llm-strong-top-k 20 \\\n",
        "    --llm-dynamic-few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ABLATION 2: No LLM (neural only)\n",
        "!python -m src.main train \\\n",
        "    --output-dir results_no_llm \\\n",
        "    --dense-index-path \"/content/drive/MyDrive/robust04_dense_index\" \\\n",
        "    --limit-queries 5 \\\n",
        "    --disable-llm \\\n",
        "    --retrieval-k 2000 \\\n",
        "    --rerank-depth 1000 \\\n",
        "    --chunk-size 512 \\\n",
        "    --chunk-overlap 64 \\\n",
        "    --use-bi-encoder \\\n",
        "    --bi-encoder-model \"BAAI/bge-large-en-v1.5\" \\\n",
        "    --bi-encoder-ratio 2.0 \\\n",
        "    --ce-model \"BAAI/bge-reranker-v2-m3,cross-encoder/ms-marco-MiniLM-L-12-v2\" \\\n",
        "    --monot5-model \"castorini/monot5-large-msmarco\" \\\n",
        "    --ce-batch-size 256 \\\n",
        "    --monot5-batch-size 64 \\\n",
        "    --ce-weight 0.5 \\\n",
        "    --neural-weight 0.8 \\\n",
        "    --rrf-k 60 \\\n",
        "    --rrf-weight-run1 1.0 \\\n",
        "    --rrf-weight-run2 1.0 \\\n",
        "    --rrf-weight-llm 1.0 \\\n",
        "    --llm-model \"gpt-4o-mini\" \\\n",
        "    --llm-top-k 50 \\\n",
        "    --llm-window-size 10 \\\n",
        "    --llm-step-size 5 \\\n",
        "    --llm-max-passage-length 1500 \\\n",
        "    --llm-concurrency 10 \\\n",
        "    --llm-strong-model \"gpt-5\" \\\n",
        "    --llm-strong-top-k 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ABLATION 3: No Q2D + No LLM (baseline neural)\n",
        "!python -m src.main train \\\n",
        "    --output-dir results_baseline \\\n",
        "    --dense-index-path \"/content/drive/MyDrive/robust04_dense_index\" \\\n",
        "    --limit-queries 5 \\\n",
        "    --disable-q2d \\\n",
        "    --disable-llm \\\n",
        "    --retrieval-k 2000 \\\n",
        "    --rerank-depth 1000 \\\n",
        "    --chunk-size 512 \\\n",
        "    --chunk-overlap 64 \\\n",
        "    --use-bi-encoder \\\n",
        "    --bi-encoder-model \"BAAI/bge-large-en-v1.5\" \\\n",
        "    --bi-encoder-ratio 2.0 \\\n",
        "    --ce-model \"BAAI/bge-reranker-v2-m3,cross-encoder/ms-marco-MiniLM-L-12-v2\" \\\n",
        "    --monot5-model \"castorini/monot5-large-msmarco\" \\\n",
        "    --ce-batch-size 256 \\\n",
        "    --monot5-batch-size 64 \\\n",
        "    --ce-weight 0.5 \\\n",
        "    --neural-weight 0.8 \\\n",
        "    --rrf-k 60 \\\n",
        "    --rrf-weight-run1 1.0 \\\n",
        "    --rrf-weight-run2 1.0 \\\n",
        "    --rrf-weight-llm 1.0 \\\n",
        "    --llm-model \"gpt-4o-mini\" \\\n",
        "    --llm-top-k 50 \\\n",
        "    --llm-window-size 10 \\\n",
        "    --llm-step-size 5 \\\n",
        "    --llm-max-passage-length 1500 \\\n",
        "    --llm-concurrency 10 \\\n",
        "    --llm-strong-model \"gpt-5\" \\\n",
        "    --llm-strong-top-k 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare ablation results\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "configs = [\n",
        "    (\"Full (Q2D + LLM)\", \"results_sanity\"),\n",
        "    (\"No Q2D\", \"results_no_q2d\"),\n",
        "    (\"No LLM\", \"results_no_llm\"),\n",
        "    (\"Baseline (no Q2D, no LLM)\", \"results_baseline\"),\n",
        "]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ABLATION COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Config':<30} {'Run1 MAP':>12} {'Run2 MAP':>12} {'Run3 MAP':>12}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for name, path in configs:\n",
        "    metrics_file = Path(path) / \"metrics.json\"\n",
        "    if metrics_file.exists():\n",
        "        with open(metrics_file) as f:\n",
        "            m = json.load(f)\n",
        "        print(f\"{name:<30} {m['run_1']['map']:>12.4f} {m['run_2']['map']:>12.4f} {m['run_3']['map']:>12.4f}\")\n",
        "    else:\n",
        "        print(f\"{name:<30} {'(not run)':>12} {'':>12} {'':>12}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Training (50 queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full training with SPLADE (~20 min with bi-encoder, ~$1.00 LLM cost)\n",
        "# 6-way hybrid retrieval: BM25 + Dense + SPLADE (orig + Q2D each)\n",
        "!python -m src.main train \\\n",
        "    --output-dir results \\\n",
        "    --dense-index-path \"/content/drive/MyDrive/robust04_dense_index\" \\\n",
        "    --splade-index-path \"/content/drive/MyDrive/robust04_splade_index\" \\\n",
        "    --retrieval-k 2000 \\\n",
        "    --rerank-depth 1000 \\\n",
        "    --chunk-size 512 \\\n",
        "    --chunk-overlap 64 \\\n",
        "    --use-bi-encoder \\\n",
        "    --bi-encoder-model \"BAAI/bge-large-en-v1.5\" \\\n",
        "    --bi-encoder-ratio 2.0 \\\n",
        "    --ce-model \"BAAI/bge-reranker-v2-m3,cross-encoder/ms-marco-MiniLM-L-12-v2\" \\\n",
        "    --monot5-model \"castorini/monot5-large-msmarco\" \\\n",
        "    --ce-batch-size 256 \\\n",
        "    --monot5-batch-size 64 \\\n",
        "    --ce-weight 0.5 \\\n",
        "    --neural-weight 0.8 \\\n",
        "    --rrf-k 60 \\\n",
        "    --rrf-weight-run1 1.0 \\\n",
        "    --rrf-weight-run2 1.0 \\\n",
        "    --rrf-weight-llm 1.0 \\\n",
        "    --llm-model \"gpt-4o-mini\" \\\n",
        "    --llm-top-k 50 \\\n",
        "    --llm-window-size 10 \\\n",
        "    --llm-step-size 5 \\\n",
        "    --llm-max-passage-length 1500 \\\n",
        "    --llm-concurrency 10 \\\n",
        "    --llm-strong-model \"gpt-5\" \\\n",
        "    --llm-strong-top-k 20 \\\n",
        "    --llm-dynamic-few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View training metrics\n",
        "import json\n",
        "with open(\"results/metrics.json\") as f:\n",
        "    metrics = json.load(f)\n",
        "for run, m in metrics.items():\n",
        "    print(f\"{run}: MAP={m['map']:.4f}  NDCG@10={m['ndcg_10']:.4f}  P@10={m['p_10']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Test Submission (199 queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test submission with SPLADE (~50-70 min with bi-encoder, ~$4.00 LLM cost)\n",
        "# 6-way hybrid retrieval: BM25 + Dense + SPLADE (orig + Q2D each)\n",
        "!python -m src.main test \\\n",
        "    --output-dir Final_Project_Part_A \\\n",
        "    --dense-index-path \"/content/drive/MyDrive/robust04_dense_index\" \\\n",
        "    --splade-index-path \"/content/drive/MyDrive/robust04_splade_index\" \\\n",
        "    --retrieval-k 2000 \\\n",
        "    --rerank-depth 1000 \\\n",
        "    --chunk-size 512 \\\n",
        "    --chunk-overlap 64 \\\n",
        "    --use-bi-encoder \\\n",
        "    --bi-encoder-model \"BAAI/bge-large-en-v1.5\" \\\n",
        "    --bi-encoder-ratio 2.0 \\\n",
        "    --ce-model \"BAAI/bge-reranker-v2-m3,cross-encoder/ms-marco-MiniLM-L-12-v2\" \\\n",
        "    --monot5-model \"castorini/monot5-large-msmarco\" \\\n",
        "    --ce-batch-size 256 \\\n",
        "    --monot5-batch-size 64 \\\n",
        "    --ce-weight 0.5 \\\n",
        "    --neural-weight 0.8 \\\n",
        "    --rrf-k 60 \\\n",
        "    --rrf-weight-run1 1.0 \\\n",
        "    --rrf-weight-run2 1.0 \\\n",
        "    --rrf-weight-llm 1.0 \\\n",
        "    --llm-model \"gpt-4o-mini\" \\\n",
        "    --llm-top-k 50 \\\n",
        "    --llm-window-size 10 \\\n",
        "    --llm-step-size 5 \\\n",
        "    --llm-max-passage-length 1500 \\\n",
        "    --llm-concurrency 10 \\\n",
        "    --llm-strong-model \"gpt-5\" \\\n",
        "    --llm-strong-top-k 20 \\\n",
        "    --llm-dynamic-few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create submission zip\n",
        "!cd Final_Project_Part_A && zip -q ../Final_Project_Part_A.zip run_1.res run_2.res run_3.res\n",
        "!ls -la Final_Project_Part_A.zip\n",
        "print(\"\\n✓ Download Final_Project_Part_A.zip\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
